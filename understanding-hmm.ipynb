{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ice-cream example\n",
    "\n",
    "states = ('HOT', 'COLD')\n",
    "symbols = ('1', '2', '3')\n",
    "\n",
    "start_prob = {\n",
    "    'HOT': 0.8,\n",
    "    'COLD': 0.2\n",
    "}\n",
    "\n",
    "trans_prob = {\n",
    "    'HOT': { 'HOT': 0.6, 'COLD': 0.4 },\n",
    "    'COLD': { 'HOT': 0.5, 'COLD': 0.5 },\n",
    "}\n",
    "\n",
    "emit_prob = {\n",
    "    'HOT': { '1': 0.2, '2': 0.4, '3': 0.4 },\n",
    "    'COLD': { '1': 0.5, '2': 0.4, '3': 0.1 },\n",
    "}\n",
    "\n",
    "sequence = ['3', '1', '3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def forward()\n",
    "# def decode()\n",
    "# def backward()\n",
    "# def learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood Computation: The Forward Algorithm\n",
    "\n",
    "- the likelihood of the observation sequence is:\n",
    "$$P(O|Q) = \\prod_{i=1}^{T} P(o_i|q_i)$$\n",
    "\n",
    "- joint probability:\n",
    "$$P(O,Q) = P(O|Q) \\times P(Q) = \\prod_{i=1}^{T} P(o_i|q_i) \\times \\prod_{i=1}^{T} P(p_i|q_{i-1})$$\n",
    "\n",
    "- total probability of the observations:\n",
    "$$P(O) = \\sum_Q P(O,Q) = \\sum_Q P(O|Q)P(Q)$$\n",
    "\n",
    "For an HMM with $N$ hidden states and an observation sequence of $T$ observations, there are $N^T$ possible hidden sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### forward algorithm - $O(N^2T)$\n",
    "- Each cell of the forward algorithm trellis $\\alpha_t(j)$ represents the probability of being in state $j$ after seeing the first $t$ observations, given the automaton $\\lambda$. The value of each cell $\\alpha_t(j)$ is computed by summing over the probabilities of every path.\n",
    "$$\\alpha_t(j) = P(o_1, o_2, \\dots o_t, q_t = j | \\lambda)$$\n",
    "- For a given state $q_j$ at time $t$, the value $\\alpha_t(j)$ is computed as:\n",
    "$$\\alpha_t(j) = \\sum_{i=1}^{N} \\alpha_{t-1}(i) a_{ij} b_j(o_t)$$\n",
    "- The three factors:\n",
    " - $\\alpha_{t-1}(i) ~~~~~ : ~$ the **previous forward path probability**\n",
    " - $a_{ij} ~~~~~~~~~~~~ : ~$the **transition probability**\n",
    " - $b_j(o_t) ~~~~~~~ : ~$ the **state observation likelihood**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialization:\n",
    "$$\\alpha_1(j) = \\pi_j b_j(o_1) \\quad 1\\le j \\le N$$\n",
    "2. Recursion:\n",
    "$$\\alpha_t(j) = \\sum_{i=1}^{N} \\alpha_{t-1}(i) a_{ij} b_j(o_t); \\quad 1 \\le j \\le N, 1 < t \\le T$$\n",
    "3. Termination:\n",
    "$$P(O|\\lambda) = \\sum_{i=1}^N \\alpha_T(i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(states, symbols, start_prob, trans_prob, emit_prob, sequence):\n",
    "    length = len(sequence)\n",
    "    \n",
    "    # t == 1, alpha_1(j) = pi_j * b_j(o_1)\n",
    "    alpha = [{}]\n",
    "    for state in states:\n",
    "        alpha[0][state] = start_prob[state] * emit_prob[state][sequence[0]]\n",
    "    \n",
    "    # t >= 2, alpha_t(j) = sum_i_N   alpha_t-1(i) * a_ij * b_j(o_t)\n",
    "    for t in range(1, length):\n",
    "        alpha.append({})\n",
    "        for state_j in states:\n",
    "            prob = 0\n",
    "            for state_i in states:\n",
    "                prob += alpha[t-1][state_i] * trans_prob[state_i][state_j] * emit_prob[state_j][sequence[t]]\n",
    "            alpha[t][state_j] = prob\n",
    "    \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'COLD': 0.020000000000000004, 'HOT': 0.32000000000000006},\n",
       " {'COLD': 0.06900000000000002, 'HOT': 0.04040000000000001},\n",
       " {'COLD': 0.005066000000000002, 'HOT': 0.02349600000000001}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(states, symbols, start_prob, trans_prob, emit_prob, sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding: The Viterbi Algorithm\n",
    "Given as input an HMM $\\lambda = (A, B)$ and a sequence of observations $O = o_1, o_2, \\dots, o_T$, find the most probable sequence of states $Q = q_1 q_2 q_3 \\dots q_T$.\n",
    "$$v_t(j) = \\text{max}_{q_1, \\dots, q_{t-1}}P(q_1 \\dots q_{t-1}, o_1, o_2, \\dots o_t, q_t = j | \\lambda)$$\n",
    "- For a given state $q_j$ at time $t$, the value $v_t(j)$ is computed as:\n",
    "$$\\alpha_t(j) = \\text{max}_{i=1}^{N} v_{t-1}(i) a_{ij} b_j(o_t)$$\n",
    "- The three factors:\n",
    " - $v_{t-1}(i) ~~~~~~ : ~$ the **previous Viterbi path probability**\n",
    " - $a_{ij} ~~~~~~~~~~~~ : ~$the **transition probability**\n",
    " - $b_j(o_t) ~~~~~~~ : ~$ the **state observation likelihood**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialization:\n",
    "$$v_1(j) = \\pi_j b_j(o_1) \\quad 1\\le j \\le N$$\n",
    "$$bt_1(j) = 0 \\quad 1\\le j \\le N$$\n",
    "2. Recursion:\n",
    "$$v_t(j) = \\text{max}_{i=1}^{N} v_{t-1}(i) a_{ij} b_j(o_t); \\quad 1 \\le j \\le N, 1 < t \\le T$$\n",
    "$$bt_t(j) = \\text{argmax}_{i=1}^{N} v_{t-1}(i) a_{ij} b_j(o_t); \\quad 1 \\le j \\le N, 1 < t \\le T$$\n",
    "3. Termination:\n",
    "$$\\text{The best score:}\\quad P* = \\text{max}_{i=1}^N v_T(i)$$\n",
    "$$\\text{The start of backtrace::}\\quad q_T* = \\text{argmax}_{i=1}^N v_T(i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(states, symbols, start_prob, trans_prob, emit_prob, sequence):\n",
    "    \"\"\"Viterbi decoding\"\"\"\n",
    "    length = len(sequence)\n",
    "    \n",
    "    # t == 1, v_1(j) = pi_j * b_j(o_1)\n",
    "    # t == 1, bt_1(j) = 0\n",
    "    V = {}\n",
    "    for state in states:\n",
    "        V[state] = start_prob[state] * emit_prob[state][sequence[0]]\n",
    "\n",
    "    # t >= 2, v_t(j) = max_i_N   v_t-1(i) * a_ij * b_j(o_t)\n",
    "    # t >= 2, bt_t(j) = argmax_i_N   v_t-1(i) * a_ij * b_j(o_t)\n",
    "    paths = []\n",
    "    for t in range(1, length):\n",
    "        V_tmp = {}\n",
    "        prev_state = {}\n",
    "        for state_j in states:\n",
    "            max_prob = 0\n",
    "            max_state = None\n",
    "            for state_i in states:\n",
    "                prob = V[state_i] * trans_prob[state_i][state_j]\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_state = state_i\n",
    "            V_tmp[state_j] = max_prob * emit_prob[state_j][sequence[t]]\n",
    "            prev_state[state_j] = max_state\n",
    "        V = V_tmp\n",
    "        paths.append(prev_state)\n",
    "    \n",
    "    # the most probable state and its backtrack\n",
    "    # find the last state (\"raniy\", because prob of 'raniy' is bigger than 'sunny' in the last V)\n",
    "    max_prob = 0\n",
    "    max_state = None\n",
    "    for state in states:\n",
    "        if V[state] > max_prob:\n",
    "            max_prob = V[state]\n",
    "            max_state = state\n",
    "    \n",
    "    result = [max_state]\n",
    "    # follow the backtrack till the first observation (T-1 ~ 1)\n",
    "    for t in range(length -1, 0, -1):\n",
    "        max_state = paths[t-1][max_state]\n",
    "        result.insert(0, max_state)\n",
    "    \n",
    "    return result, V, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['HOT', 'COLD', 'HOT'],\n",
       " {'COLD': 0.003200000000000001, 'HOT': 0.012800000000000004},\n",
       " [{'COLD': 'HOT', 'HOT': 'HOT'}, {'COLD': 'COLD', 'HOT': 'COLD'}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(states, symbols, start_prob, trans_prob, emit_prob, sequence)\n",
    "# paths means {to: from}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'COLD': 0.020000000000000004, 'HOT': 0.32000000000000006},\n",
       " {'COLD': 0.06900000000000002, 'HOT': 0.04040000000000001},\n",
       " {'COLD': 0.005066000000000002, 'HOT': 0.02349600000000001}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(states, symbols, start_prob, trans_prob, emit_prob, sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Training: The Forward-Backward Algorithm\n",
    "- The backward probability $\\beta$ is the probability of seeing the observations from time $t+1$ to the end, given that we are in state $i$ at time $t$ (and given the automaton $\\lambda$):\n",
    "$$\\beta_t(i) = P(o_{t+1}, o_{t+2}, \\dots o_T | q_t = i, \\lambda)$$\n",
    "\n",
    "\n",
    "1. Initialization:\n",
    "$$\\beta_T(i) = 1 \\quad 1\\le j \\le N$$\n",
    "2. Recursion:\n",
    "$$\\beta_t(i) = \\sum_{j=1}^{N} a_{ij} b_j(o_{t+1}) \\beta_{t+1}(j); \\quad 1 \\le i \\le N, 1 \\le t < T$$\n",
    "3. Termination:\n",
    "$$P(O|\\lambda) = \\sum_{j=1}^N \\pi_j b_j(o_1) \\beta_1(j)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward(states, symbols, start_prob, trans_prob, emit_prob, sequence):\n",
    "    length = len(sequence)\n",
    "    \n",
    "    # t == T, beta_T(i) = 1\n",
    "    beta = [{}]\n",
    "    for state in states:\n",
    "        beta[0][state] = 1\n",
    "    \n",
    "    # t <= T-1, beta_t(i) = sum_j_N   a_ij * b_j(o_t+1) * beta_t+1(j)\n",
    "    for t in range(length-1, 0, -1):\n",
    "        beta.insert(0, {})\n",
    "        for state_i in states:\n",
    "            prob = 0\n",
    "            for state_j in states:\n",
    "                prob += emit_prob[state_j][sequence[t]] * beta[1][state_j] * trans_prob[state_i][state_j]\n",
    "            beta[0][state_i] = prob\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'COLD': 0.0905, 'HOT': 0.08360000000000001},\n",
       " {'COLD': 0.25, 'HOT': 0.28},\n",
       " {'COLD': 1, 'HOT': 1}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward(states, symbols, start_prob, trans_prob, emit_prob, sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the tarnsition probability; $\\hat{a}_{ij}$\n",
    "$$\\hat{\\alpha}_{ij} = \\frac{\\text{expected number of transitions from state } i \\text{ to state } j}{\\text{expected number of transitions from state }i}$$\n",
    "\n",
    "- The probability of being in state $i$ at itme $t$ and state $j$ at time $t+1$, given the observations sequence and of course the model:\n",
    "$$\\xi_t(i, j) = P(q_t = i, q_{t+1} = j | O, \\lambda)$$\n",
    "\n",
    "\n",
    "- To compute $\\xi_t$, we first compute a probability which is similar to $\\xi_t$, but differs in including the probability of the observation; note the different conditioning of $O$:\n",
    "$$\\text{non-quite-}\\xi_t(i, j) = P(q_t = i, q_{t+1} = j , O|\\lambda)$$\n",
    "\n",
    "\n",
    "- The four different probabilities are multiplied together to produce *not-quite-$\\xi_t$* as follows:\n",
    "$$\\text{non-quite-}\\xi_t(i, j) = \\alpha_t(i) a_{ij} b_j(o_{t+1}) \\beta_{t+1}(j)$$\n",
    "\n",
    "\n",
    "- The probability of the observation given the model is simply the forward probability of the whole utterance (or the backward)\n",
    "$$P(O|\\lambda) = \\sum_{j=1}^N \\alpha_t(j) \\beta_t(j)$$\n",
    "- So, the final equation for $\\xi_t$ is\n",
    "$$\\xi_t(i, j) = \\frac{\\alpha_t(i) a_{ij} b_j(o_{t+1}) \\beta_{t+1}(j)}{\\sum_{j=1}^N \\alpha_t(j) \\beta_t(j)}$$\n",
    "\n",
    "$$\\hat{\\alpha}_{ij} = \\frac{\\sum_{t=1}^{T-1} \\xi_t(i, j)}{\\sum_{t=1}^{T-1}\\sum_{k=1}^{N} \\xi_t(i, k)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the observation probability;  $\\hat{b}_j(v_k)$\n",
    "$$\\hat{b}_j(v_k) = \\frac{\\text{expected number of times in state } j \\text{ and observing symbol } v_k}{\\text{expected number of times in state }j}$$\n",
    "\n",
    "- The probability of being in state $j$ at time $t$, which we will call $\\gamma_t(j)$:\n",
    "$$\\gamma_t(j) = P(q_t = j | O, \\lambda)$$\n",
    "\n",
    "\n",
    "- Once again, we will compute this by including the observation sequence in the probability:\n",
    "$$\\gamma_t(j) = \\frac{P(q_t = j, O | \\lambda)}{P(O|\\lambda)}$$\n",
    "\n",
    "\n",
    "- Note that $\\gamma$ is really a degenerate case of $\\xi$ (state $i$ collapsed with state $j$):\n",
    "$$\\gamma_t(j) = \\frac{\\alpha_t(j) \\beta_t(j)}{P(O|\\lambda)}$$\n",
    "\n",
    "- The result is the percentage of the times that we were in state $j$ and saw symbol $v_k$:\n",
    "$$\\hat{b}_j(v_k) = \\frac{\\sum_{t=1 s.t. O_t=v_k}^{T} \\gamma_t(j)}{\\sum_{t=1}^{T} \\gamma_t(j)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Like other cases of the EM (expectation-maximization) algorithm, the forward-backward algorithm has two steps:\n",
    "- the **expectation** step, or **E-step**\n",
    " - we compute the expected state occupancy count $\\gamma$ and the expected state trasition count $\\xi$ from the earlier $A$ and $B$ probabilities.\n",
    "- the **maximazation** step, or **M-step**\n",
    " - we use $\\gamma$ and $\\xi$ to recompute new $A$ and $B$ probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn(states, symbols, start_prob, trans_prob, emit_prob, sequence):\n",
    "    length = len(sequence)\n",
    "    alpha = forward(states, symbols, start_prob, trans_prob, emit_prob, sequence)\n",
    "    beta = backward(states, symbols, start_prob, trans_prob, emit_prob, sequence)\n",
    "    \n",
    "    # E-step: gamma_t(j) = (alpha_t(j) * beta_t(j)) / alpha_T(q_F)\n",
    "    gamma = []\n",
    "    for t in range(length):\n",
    "        prob_sum = 0\n",
    "        gamma.append({})\n",
    "        for state in states:\n",
    "            prob = alpha[t][state] * beta[t][state]\n",
    "            prob_sum += prob\n",
    "            gamma[t][state] = prob\n",
    "        # dividing\n",
    "        for state in states:\n",
    "            gamma[t][state] /= prob_sum\n",
    "            \n",
    "    # E-step: xi_t(i, j) = (alpha_t(i) * a_ij * b_j(o_t+1) * beta_t+1(j)) / alpha_T(q_F)\n",
    "    xi = []\n",
    "    for t in range(length-1):\n",
    "        prob_sum = 0\n",
    "        xi.append({})\n",
    "        for state_i in states:\n",
    "            xi[t][state_i] = {}\n",
    "            for state_j in states:\n",
    "                prob = alpha[t][state_i] * trans_prob[state_i][state_j] * \\\n",
    "                    emit_prob[state_j][sequence[t+1]] * beta[t+1][state_j]\n",
    "                xi[t][state_i][state_j] = prob\n",
    "                prob_sum += prob       \n",
    "        # dividing\n",
    "        for state_i in states:\n",
    "            for state_j in states:\n",
    "                xi[t][state_i][state_j] /= prob_sum\n",
    "\n",
    "    return gamma, xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'COLD': 0.06337091240109236, 'HOT': 0.9366290875989077},\n",
       "  {'COLD': 0.6039493032700791, 'HOT': 0.3960506967299209},\n",
       "  {'COLD': 0.1773685316154331, 'HOT': 0.8226314683845669}],\n",
       " [{'COLD': {'COLD': 0.04376444226594776, 'HOT': 0.019606470135144598},\n",
       "   'HOT': {'COLD': 0.5601848610041312, 'HOT': 0.3764442265947763}},\n",
       "  {'COLD': {'COLD': 0.12078986065401583, 'HOT': 0.4831594426160633},\n",
       "   'HOT': {'COLD': 0.05657867096141726, 'HOT': 0.3394720257685036}}])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn(states, symbols, start_prob, trans_prob, emit_prob, sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = [{'COLD': 0.06337091240109236, 'HOT': 0.9366290875989077},\n",
    "         \n",
    "         {'COLD': 0.6039493032700791, 'HOT': 0.3960506967299209},\n",
    "      \n",
    "         {'COLD': 0.1773685316154331, 'HOT': 0.8226314683845669}]\n",
    "\n",
    "xi = [{'COLD': {'COLD': 0.04376444226594776, 'HOT': 0.019606470135144598},\n",
    "       'HOT': {'COLD': 0.5601848610041312, 'HOT': 0.3764442265947763}},\n",
    "      \n",
    "      {'COLD': {'COLD': 0.12078986065401583, 'HOT': 0.4831594426160633},\n",
    "       'HOT': {'COLD': 0.05657867096141726, 'HOT': 0.3394720257685036}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06337091240109236"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time 1 -> to cold from cold + hot = gamma cold time 1\n",
    ".04376444226594776 + .019606470135144598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6039493032700791"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time 2 -> to cold from cold + hot = gamma cold time 2\n",
    ".12078986065401583 + .4831594426160633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2465897166841553"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time 1 + 2 -> to cold / all prob from cold\n",
    "(.04376444226594776 + .12078986065401583) / \\\n",
    "(.04376444226594776 +.019606470135144598 +.12078986065401583 +.4831594426160633)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivation: $\\sum_{t=1}^{T-1} \\gamma_t(j) = \\sum_{t=1}^{T-1}\\sum_{k=1}^{N} \\xi_t(i, k)$\n",
    "\n",
    " \n",
    "1. $$\\sum_{t=1}^{T-1} \\gamma_t(j) = \\sum_{t=1}^{T-1} \\alpha_t(j) \\beta_t(j)$$\n",
    "\n",
    "2. \n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{t=1}^{T-1}\\sum_{k=1}^{N} \\xi_t(i, k) &= \\sum_{t=1}^{T-1}\\sum_{k=1}^{N} \\alpha_t(i) a_{ij} b_j(o_{t+1}) \\\\\n",
    "&= \\sum_{t=1}^{T-1} \\alpha_t(i) \\sum_{k=1}^{N} a_{ij} b_j(o_{t+1}) \\\\\n",
    "&= \\sum_{t=1}^{T-1} \\alpha_t(j) \\beta_t(j) \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COLD': {'COLD': 0.2465897166841553, 'HOT': 0.7534102833158446},\n",
       " 'HOT': {'COLD': 0.4627994955863806, 'HOT': 0.537200504413619}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M-step: re-estimate transition prob (A)\n",
    "# gamma_sum by state through time (same)\n",
    "\n",
    "for state in states:\n",
    "    gamma_sum = 0\n",
    "    for index in range(2):\n",
    "        gamma_sum += gamma[index][state]\n",
    "#     print(gamma_sum, \"({})\".format(state))\n",
    "\n",
    "    denominator = gamma_sum\n",
    "    for state_to in states:\n",
    "        xi_sum = 0\n",
    "        for index in range(2):\n",
    "            xi_sum += xi[index][state][state_to]\n",
    "#         print(\"xi_sum: \", xi_sum, \"denominater: \", denominator)\n",
    "        trans_prob[state][state_to] = xi_sum / denominator\n",
    "\n",
    "trans_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3326797843288285 (HOT)\n",
      "xi_sum:  0.7159162523632798 denominater:  1.3326797843288285\n",
      "xi_sum:  0.6167635319655485 denominater:  1.3326797843288285\n",
      "0.6673202156711715 (COLD)\n",
      "xi_sum:  0.5027659127512079 denominater:  0.6673202156711715\n",
      "xi_sum:  0.1645543029199636 denominater:  0.6673202156711715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'COLD': {'COLD': 0.2465897166841553, 'HOT': 0.7534102833158446},\n",
       " 'HOT': {'COLD': 0.4627994955863807, 'HOT': 0.5372005044136191}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M-step: re-estimate transition prob (A)\n",
    "# xi_sum by state through time (same)\n",
    "\n",
    "for state in states:\n",
    "    denominator = 0\n",
    "    for state_to in states:\n",
    "        for index in range(2):\n",
    "            denominator += xi[index][state][state_to]\n",
    "    print(denominator, \"({})\".format(state))\n",
    "            \n",
    "    for state_to in states:\n",
    "        xi_sum = 0\n",
    "        for index in range(2):\n",
    "            xi_sum += xi[index][state][state_to]\n",
    "        print(\"xi_sum: \", xi_sum, \"denominater: \", denominator)\n",
    "        trans_prob[state][state_to] = xi_sum / denominator\n",
    "    \n",
    "trans_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma = [{'COLD': 0.06337091240109236, 'HOT': 0.9366290875989077},\n",
    "         \n",
    "         {'COLD': 0.6039493032700791, 'HOT': 0.3960506967299209},\n",
    "      \n",
    "         {'COLD': 0.1773685316154331, 'HOT': 0.8226314683845669}]\n",
    "\n",
    "xi = [{'COLD': {'COLD': 0.04376444226594776, 'HOT': 0.019606470135144598},\n",
    "       'HOT': {'COLD': 0.5601848610041312, 'HOT': 0.3764442265947763}},\n",
    "      \n",
    "      {'COLD': {'COLD': 0.12078986065401583, 'HOT': 0.4831594426160633},\n",
    "       'HOT': {'COLD': 0.05657867096141726, 'HOT': 0.3394720257685036}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(HOT)\n",
      "0.9366290875989077 (3)\n",
      "0.3960506967299209 (1)\n",
      "0.8226314683845669 (3)\n",
      "{'2': 0, '3': 1.7592605559834746, '1': 0.3960506967299209} (HOT) 2.1553112527133957\n",
      "(COLD)\n",
      "0.06337091240109236 (3)\n",
      "0.6039493032700791 (1)\n",
      "0.1773685316154331 (3)\n",
      "{'2': 0, '3': 0.24073944401652544, '1': 0.6039493032700791} (COLD) 0.8446887472866046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'COLD': {'1': 0.7149962695846804, '2': 0.0, '3': 0.28500373041531957},\n",
       " 'HOT': {'1': 0.18375568551007146, '2': 0.0, '3': 0.8162443144899284}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M-step: re-estimate emission prob (B)\n",
    "\n",
    "for state in states:\n",
    "    gamma_sum = 0\n",
    "    for index in range(2):\n",
    "        gamma_sum += gamma[index][state]\n",
    "#     print(gamma_sum, \"({})\".format(state))\n",
    "\n",
    "    denominator = gamma_sum\n",
    "    for state_to in states:\n",
    "        xi_sum = 0\n",
    "        for index in range(2):\n",
    "            xi_sum += xi[index][state][state_to]\n",
    "#         print(\"xi_sum: \", xi_sum, \"denominater: \", denominator)\n",
    "        trans_prob[state][state_to] = xi_sum / denominator\n",
    "\n",
    "    print(\"({})\".format(state))\n",
    "    gamma_sum += gamma[2][state]\n",
    "    emit_gamma_sum = {}\n",
    "    for symbol in symbols:\n",
    "        emit_gamma_sum[symbol] = 0\n",
    "    \n",
    "    for index in range(3):\n",
    "        print(gamma[index][state], \"({})\".format(sequence[index]))\n",
    "        emit_gamma_sum[sequence[index]] += gamma[index][state]\n",
    "    \n",
    "    denominator = gamma_sum\n",
    "    print(emit_gamma_sum, \"({})\".format(state), denominator)\n",
    "\n",
    "    for symbol in symbols:\n",
    "        emit_prob[state][symbol] = emit_gamma_sum[symbol] / denominator\n",
    "        \n",
    "emit_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1553112527133957"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".9366290875989077 + .3960506967299209 + .8226314683845669"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
